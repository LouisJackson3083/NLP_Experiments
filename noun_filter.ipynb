{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.probability import FreqDist, ConditionalFreqDist\n",
    "text_tags = nltk.corpus.brown.tagged_words(tagset='universal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1161192\n",
      "<class 'nltk.corpus.reader.util.ConcatenatedCorpusView'>\n",
      "[('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "print(len(text_tags))\n",
    "print(type(text_tags))\n",
    "print(text_tags[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All identified POS in corpus: {'PRT', 'CONJ', 'X', 'PRON', 'NUM', 'DET', 'ADV', 'VERB', '.', 'NOUN', 'ADJ', 'ADP'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "lst = np.array(text_tags)\n",
    "print(\"All identified POS in corpus:\",set(lst[:,1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say I want to filter out NOUNS and PRONOUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True ... False False False]\n",
      "[['Fulton' 'NOUN']\n",
      " ['County' 'NOUN']\n",
      " ['Jury' 'NOUN']\n",
      " ...\n",
      " ['figure' 'NOUN']\n",
      " ['boucle' 'NOUN']\n",
      " ['dress' 'NOUN']]\n"
     ]
    }
   ],
   "source": [
    "print(lst[:,1] == 'NOUN')\n",
    "lst_mask = lst[:,1] == 'NOUN'\n",
    "noun_lst = lst[lst_mask] \n",
    "print(noun_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\neoni\\OneDrive\\Documents\\UNI\\COMP34711_NLP\\noun_filter.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/COMP34711_NLP/noun_filter.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Word2Vec\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/COMP34711_NLP/noun_filter.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m Word2Vec\u001b[39m.\u001b[39mload(path\u001b[39m/\u001b[39mto\u001b[39m/\u001b[39myour\u001b[39m/\u001b[39mmodel)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/COMP34711_NLP/noun_filter.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39msimilarity(\u001b[39m'\u001b[39m\u001b[39mapple\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39morange\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec.load(path/to/your/model)\n",
    "\n",
    "model.similarity('apple', 'orange')\n",
    "\n",
    "# for i in range(10):\n",
    "#     noun = noun_lst[i,0]\n",
    "#     print(wn.synsets(noun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'isalpha'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\neoni\\OneDrive\\Documents\\UNI\\COMP34711_NLP\\noun_filter.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/COMP34711_NLP/noun_filter.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(text\u001b[39m.\u001b[39;49msimilar(\u001b[39m'\u001b[39;49m\u001b[39mwoman\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\neoni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\text.py:496\u001b[0m, in \u001b[0;36mText.similar\u001b[1;34m(self, word, num)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[39mDistributional similarity: find other words which appear in the\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[39msame contexts as the specified word; list most similar words first.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[39m:seealso: ContextIndex.similar_words()\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_word_context_index\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[0;32m    495\u001b[0m     \u001b[39m# print('Building word-context index...')\u001b[39;00m\n\u001b[1;32m--> 496\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_word_context_index \u001b[39m=\u001b[39m ContextIndex(\n\u001b[0;32m    497\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokens, \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m x: x\u001b[39m.\u001b[39;49misalpha(), key\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m s: s\u001b[39m.\u001b[39;49mlower()\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39m# words = self._word_context_index.similar_words(word, num)\u001b[39;00m\n\u001b[0;32m    502\u001b[0m word \u001b[39m=\u001b[39m word\u001b[39m.\u001b[39mlower()\n",
      "File \u001b[1;32mc:\\Users\\neoni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\text.py:61\u001b[0m, in \u001b[0;36mContextIndex.__init__\u001b[1;34m(self, tokens, context_func, filter, key)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_context_func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_default_context\n\u001b[0;32m     60\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mfilter\u001b[39m:\n\u001b[1;32m---> 61\u001b[0m     tokens \u001b[39m=\u001b[39m [t \u001b[39mfor\u001b[39;49;00m t \u001b[39min\u001b[39;49;00m tokens \u001b[39mif\u001b[39;49;00m \u001b[39mfilter\u001b[39;49m(t)]\n\u001b[0;32m     62\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_word_to_contexts \u001b[39m=\u001b[39m CFD(\n\u001b[0;32m     63\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_key(w), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_context_func(tokens, i)) \u001b[39mfor\u001b[39;00m i, w \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tokens)\n\u001b[0;32m     64\u001b[0m )\n\u001b[0;32m     65\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_context_to_words \u001b[39m=\u001b[39m CFD(\n\u001b[0;32m     66\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_context_func(tokens, i), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_key(w)) \u001b[39mfor\u001b[39;00m i, w \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tokens)\n\u001b[0;32m     67\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\neoni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\text.py:61\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_context_func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_default_context\n\u001b[0;32m     60\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mfilter\u001b[39m:\n\u001b[1;32m---> 61\u001b[0m     tokens \u001b[39m=\u001b[39m [t \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tokens \u001b[39mif\u001b[39;00m \u001b[39mfilter\u001b[39;49m(t)]\n\u001b[0;32m     62\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_word_to_contexts \u001b[39m=\u001b[39m CFD(\n\u001b[0;32m     63\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_key(w), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_context_func(tokens, i)) \u001b[39mfor\u001b[39;00m i, w \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tokens)\n\u001b[0;32m     64\u001b[0m )\n\u001b[0;32m     65\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_context_to_words \u001b[39m=\u001b[39m CFD(\n\u001b[0;32m     66\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_context_func(tokens, i), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_key(w)) \u001b[39mfor\u001b[39;00m i, w \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tokens)\n\u001b[0;32m     67\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\neoni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\text.py:497\u001b[0m, in \u001b[0;36mText.similar.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[39mDistributional similarity: find other words which appear in the\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[39msame contexts as the specified word; list most similar words first.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[39m:seealso: ContextIndex.similar_words()\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_word_context_index\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[0;32m    495\u001b[0m     \u001b[39m# print('Building word-context index...')\u001b[39;00m\n\u001b[0;32m    496\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_word_context_index \u001b[39m=\u001b[39m ContextIndex(\n\u001b[1;32m--> 497\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokens, \u001b[39mfilter\u001b[39m\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39;49misalpha(), key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m s: s\u001b[39m.\u001b[39mlower()\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39m# words = self._word_context_index.similar_words(word, num)\u001b[39;00m\n\u001b[0;32m    502\u001b[0m word \u001b[39m=\u001b[39m word\u001b[39m.\u001b[39mlower()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'isalpha'"
     ]
    }
   ],
   "source": [
    "print(text.similar('woman')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
