{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "### Method (b) - Dense Static Representation\n",
    "\n",
    "First we import all the libraries we want for this method, and import the training and test csv's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import re\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_df = pd.read_csv('./Training-dataset.csv')\n",
    "test_df = pd.read_csv('./Task-1-validation-dataset.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's clean up the training dataset's synopses to have no punctuation, tags, numbers or special characters.\n",
    "This will get us an array of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_return_sentences(synopses):\n",
    "    cleaned_sentences = []\n",
    "\n",
    "    for synopsis in synopses:\n",
    "        sentences = re.split(r'\\.|\\?|\\!', synopsis) # split the title/synopsis into sentences\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            # get a set of the stopwords to remove\n",
    "            stop_words = set(stopwords.words('english'))\n",
    "            # for sentence in sent_tokenize(synopsis):\n",
    "            # Remove non-alphabetic characters and convert to lowercase\n",
    "            sentence = re.sub('[^a-zA-Z]', ' ', sentence).lower()\n",
    "            # Tokenise the sentence\n",
    "            sentence = word_tokenize(sentence)\n",
    "            # Remove stopwords\n",
    "            sentence = [word for word in sentence if word not in stop_words]\n",
    "            # Lemmatize the words\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            sentence = [lemmatizer.lemmatize(word) for word in sentence]\n",
    "            sentence = ' '.join(sentence)\n",
    "        \n",
    "            cleaned_sentences.append(sentence)\n",
    "    \n",
    "    return cleaned_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\neoni\\OneDrive\\Documents\\UNI\\COMP34711_NLP\\cw\\task1.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/COMP34711_NLP/cw/task1.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m train_df[\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m train_df[\u001b[39m'\u001b[39m\u001b[39mplot_synopsis\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/COMP34711_NLP/cw/task1.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_df\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mplot_synopsis\u001b[39m\u001b[39m'\u001b[39m], inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/COMP34711_NLP/cw/task1.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m cleaned_sentences \u001b[39m=\u001b[39m preprocess_and_return_sentences(\u001b[39mlist\u001b[39;49m(train_df[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m]))\n",
      "\u001b[1;32mc:\\Users\\neoni\\OneDrive\\Documents\\UNI\\COMP34711_NLP\\cw\\task1.ipynb Cell 5\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/COMP34711_NLP/cw/task1.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m sentences \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msplit(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m.|\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m?|\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m!\u001b[39m\u001b[39m'\u001b[39m, synopsis) \u001b[39m# split the title/synopsis into sentences\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/COMP34711_NLP/cw/task1.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m sentences:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/COMP34711_NLP/cw/task1.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# get a set of the stopwords to remove\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/COMP34711_NLP/cw/task1.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     stop_words \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(stopwords\u001b[39m.\u001b[39;49mwords(\u001b[39m'\u001b[39;49m\u001b[39menglish\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/COMP34711_NLP/cw/task1.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# for sentence in sent_tokenize(synopsis):\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/COMP34711_NLP/cw/task1.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m# Remove non-alphabetic characters and convert to lowercase\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/COMP34711_NLP/cw/task1.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     sentence \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39m'\u001b[39m\u001b[39m[^a-zA-Z]\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m, sentence)\u001b[39m.\u001b[39mlower()\n",
      "File \u001b[1;32mc:\\Users\\neoni\\OneDrive\\Documents\\UNI\\COMP34711_NLP\\venv\\Lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py:21\u001b[0m, in \u001b[0;36mWordListCorpusReader.words\u001b[1;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwords\u001b[39m(\u001b[39mself\u001b[39m, fileids\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, ignore_lines_startswith\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m     20\u001b[0m         line\n\u001b[1;32m---> 21\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m line_tokenize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw(fileids))\n\u001b[0;32m     22\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m line\u001b[39m.\u001b[39mstartswith(ignore_lines_startswith)\n\u001b[0;32m     23\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\neoni\\OneDrive\\Documents\\UNI\\COMP34711_NLP\\venv\\Lib\\site-packages\\nltk\\corpus\\reader\\api.py:218\u001b[0m, in \u001b[0;36mCorpusReader.raw\u001b[1;34m(self, fileids)\u001b[0m\n\u001b[0;32m    216\u001b[0m contents \u001b[39m=\u001b[39m []\n\u001b[0;32m    217\u001b[0m \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m fileids:\n\u001b[1;32m--> 218\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopen(f) \u001b[39mas\u001b[39;00m fp:\n\u001b[0;32m    219\u001b[0m         contents\u001b[39m.\u001b[39mappend(fp\u001b[39m.\u001b[39mread())\n\u001b[0;32m    220\u001b[0m \u001b[39mreturn\u001b[39;00m concat(contents)\n",
      "File \u001b[1;32mc:\\Users\\neoni\\OneDrive\\Documents\\UNI\\COMP34711_NLP\\venv\\Lib\\site-packages\\nltk\\corpus\\reader\\api.py:231\u001b[0m, in \u001b[0;36mCorpusReader.open\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[39mReturn an open stream that can be used to read the given file.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[39mIf the file's encoding is not None, then the stream will\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39m:param file: The file identifier of the file to read.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    230\u001b[0m encoding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding(file)\n\u001b[1;32m--> 231\u001b[0m stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_root\u001b[39m.\u001b[39;49mjoin(file)\u001b[39m.\u001b[39mopen(encoding)\n\u001b[0;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m stream\n",
      "File \u001b[1;32mc:\\Users\\neoni\\OneDrive\\Documents\\UNI\\COMP34711_NLP\\venv\\Lib\\site-packages\\nltk\\data.py:334\u001b[0m, in \u001b[0;36mFileSystemPathPointer.join\u001b[1;34m(self, fileid)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjoin\u001b[39m(\u001b[39mself\u001b[39m, fileid):\n\u001b[0;32m    333\u001b[0m     _path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path, fileid)\n\u001b[1;32m--> 334\u001b[0m     \u001b[39mreturn\u001b[39;00m FileSystemPathPointer(_path)\n",
      "File \u001b[1;32mc:\\Users\\neoni\\OneDrive\\Documents\\UNI\\COMP34711_NLP\\venv\\Lib\\site-packages\\nltk\\compat.py:41\u001b[0m, in \u001b[0;36mpy3_data.<locals>._decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_decorator\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     40\u001b[0m     args \u001b[39m=\u001b[39m (args[\u001b[39m0\u001b[39m], add_py3_data(args[\u001b[39m1\u001b[39m])) \u001b[39m+\u001b[39m args[\u001b[39m2\u001b[39m:]\n\u001b[1;32m---> 41\u001b[0m     \u001b[39mreturn\u001b[39;00m init_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\neoni\\OneDrive\\Documents\\UNI\\COMP34711_NLP\\venv\\Lib\\site-packages\\nltk\\data.py:311\u001b[0m, in \u001b[0;36mFileSystemPathPointer.__init__\u001b[1;34m(self, _path)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[39mCreate a new path pointer for the given absolute path.\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \n\u001b[0;32m    307\u001b[0m \u001b[39m:raise IOError: If the given path does not exist.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    310\u001b[0m _path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(_path)\n\u001b[1;32m--> 311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mexists(_path):\n\u001b[0;32m    312\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo such file or directory: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m _path)\n\u001b[0;32m    313\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path \u001b[39m=\u001b[39m _path\n",
      "File \u001b[1;32m<frozen genericpath>:19\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_df['text'] = train_df['title'] + ' ' + train_df['plot_synopsis']\n",
    "train_df.drop(columns=['title','plot_synopsis'], inplace=True)\n",
    "cleaned_sentences = preprocess_and_return_sentences(list(train_df['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the model. This is where all the hyper parameters are set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(cleaned_sentences, vector_size=200, window=1, min_count=1, workers=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a cosine similarity function.\n",
    "\n",
    "This function takes in a model, and 2 words to find the cosine distance between.\n",
    "\n",
    "We return 0 if the word is OOV (out of vocabulary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Key 'bone' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\neoni\\OneDrive\\Documents\\UNI\\COMP34711_NLP\\cw\\task1.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/COMP34711_NLP/cw/task1.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m distance\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/COMP34711_NLP/cw/task1.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(cosine_similarity(w2v, \u001b[39m'\u001b[39m\u001b[39mbone\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mteeth\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/neoni/OneDrive/Documents/UNI/COMP34711_NLP/cw/task1.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(w2v\u001b[39m.\u001b[39;49mwv\u001b[39m.\u001b[39;49msimilarity(\u001b[39m'\u001b[39;49m\u001b[39mbone\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mteeth\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\neoni\\OneDrive\\Documents\\UNI\\COMP34711_NLP\\venv\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:1234\u001b[0m, in \u001b[0;36mKeyedVectors.similarity\u001b[1;34m(self, w1, w2)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msimilarity\u001b[39m(\u001b[39mself\u001b[39m, w1, w2):\n\u001b[0;32m   1219\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute cosine similarity between two keys.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1232\u001b[0m \n\u001b[0;32m   1233\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1234\u001b[0m     \u001b[39mreturn\u001b[39;00m dot(matutils\u001b[39m.\u001b[39munitvec(\u001b[39mself\u001b[39;49m[w1]), matutils\u001b[39m.\u001b[39munitvec(\u001b[39mself\u001b[39m[w2]))\n",
      "File \u001b[1;32mc:\\Users\\neoni\\OneDrive\\Documents\\UNI\\COMP34711_NLP\\venv\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:403\u001b[0m, in \u001b[0;36mKeyedVectors.__getitem__\u001b[1;34m(self, key_or_keys)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Get vector representation of `key_or_keys`.\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \n\u001b[0;32m    391\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    400\u001b[0m \n\u001b[0;32m    401\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key_or_keys, _KEY_TYPES):\n\u001b[1;32m--> 403\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_vector(key_or_keys)\n\u001b[0;32m    405\u001b[0m \u001b[39mreturn\u001b[39;00m vstack([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_vector(key) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m key_or_keys])\n",
      "File \u001b[1;32mc:\\Users\\neoni\\OneDrive\\Documents\\UNI\\COMP34711_NLP\\venv\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:446\u001b[0m, in \u001b[0;36mKeyedVectors.get_vector\u001b[1;34m(self, key, norm)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_vector\u001b[39m(\u001b[39mself\u001b[39m, key, norm\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    423\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get the key's vector, as a 1D numpy array.\u001b[39;00m\n\u001b[0;32m    424\u001b[0m \n\u001b[0;32m    425\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    444\u001b[0m \n\u001b[0;32m    445\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 446\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_index(key)\n\u001b[0;32m    447\u001b[0m     \u001b[39mif\u001b[39;00m norm:\n\u001b[0;32m    448\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfill_norms()\n",
      "File \u001b[1;32mc:\\Users\\neoni\\OneDrive\\Documents\\UNI\\COMP34711_NLP\\venv\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:420\u001b[0m, in \u001b[0;36mKeyedVectors.get_index\u001b[1;34m(self, key, default)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m default\n\u001b[0;32m    419\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mKey \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m not present\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key 'bone' not present\""
     ]
    }
   ],
   "source": [
    "def cosine_similarity(model, word_a, word_b):\n",
    "    try:\n",
    "        vector_a = model.wv[word_a]\n",
    "    except:\n",
    "        return 0\n",
    "    try:\n",
    "        vector_b = model.wv[word_b]\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "    distance = np.dot(vector_a, vector_b) / (np.linalg.norm(vector_a) * np.linalg.norm(vector_b))\n",
    "    \n",
    "    return distance\n",
    "\n",
    "print(cosine_similarity(w2v, 'bone', 'teeth'))\n",
    "print(w2v.wv.similarity('bone', 'teeth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 absorb learn 0.21107265\n",
      "2 absorb withdraw 0.2012277\n",
      "3 achieve accomplish 0.6727188\n",
      "4 achieve try 0.035309363\n",
      "6 acquire get 0.3384742\n",
      "7 acquire obtain 0.74875534\n",
      "8 acquire find 0.3213722\n",
      "11 apple sauce 0.3679599\n",
      "12 apple lemon 0.28626597\n",
      "13 apple sunshine 0.21503901\n",
      "14 area region 0.4900146\n",
      "16 area corner 0.3002885\n",
      "17 arm shoulder 0.6949253\n",
      "20 arm body 0.25594124\n",
      "21 arm vein 0.43120506\n",
      "22 arm knee 0.5763541\n",
      "23 arm bone 0.328757\n",
      "24 arm neck 0.65325624\n",
      "25 ball cannon 0.2836745\n",
      "26 ball basket 0.30106795\n",
      "29 bath trick 0.09466636\n",
      "30 bath wife 0.05536081\n",
      "31 bath balloon 0.41660836\n",
      "32 bed bedroom 0.64905345\n",
      "33 bed blanket 0.526487\n",
      "34 bed crib 0.56472844\n",
      "35 bed hospital 0.31625187\n",
      "38 bed chair 0.60574293\n",
      "39 belief opinion 0.46524096\n",
      "40 belief concept 0.59252495\n",
      "41 belief impression 0.2500459\n",
      "42 belief flower 0.1674661\n",
      "43 bird hawk 0.33926216\n",
      "44 bird turkey 0.20032915\n",
      "45 bird hen 0.09921355\n",
      "46 bird cock 0.25659618\n",
      "48 bone jaw 0.44865564\n",
      "49 bone ankle 0.36919773\n",
      "50 bone knee 0.36760485\n",
      "51 bone neck 0.30208135\n",
      "52 bone teeth 0.43253714\n",
      "53 bone elbow 0.3754059\n",
      "55 book literature 0.37608948\n",
      "56 book story 0.43603393\n",
      "57 book bible 0.7178749\n",
      "58 book topic 0.2588616\n",
      "59 book information 0.20158581\n",
      "60 book essay 0.43515596\n",
      "61 book article 0.62815905\n",
      "62 book theme 0.27915668\n",
      "64 boy brother 0.3729232\n",
      "65 boy soldier 0.27912918\n",
      "67 cat lion 0.4238859\n",
      "68 cat pet 0.49111274\n",
      "69 cat rabbit 0.48546484\n",
      "72 clothes drawer 0.38027206\n",
      "73 clothes fabric 0.13704403\n",
      "74 clothes button 0.22645247\n",
      "75 clothes coat 0.59003407\n",
      "76 clothes jacket 0.46546075\n",
      "77 create make 0.4128401\n",
      "80 create destroy 0.5353526\n",
      "81 cup cone 0.14123929\n",
      "82 cup jar 0.42712763\n",
      "83 cup tableware 0\n",
      "84 cup artifact 0.20698632\n",
      "85 cup object 0.20205852\n",
      "86 cup entity 0.093918204\n",
      "87 cup food 0.3749807\n",
      "88 cup article -0.0008410863\n",
      "89 cup substance 0.19488138\n",
      "90 drink eat 0.58961856\n",
      "91 drink car 0.1328586\n",
      "92 drink mother 0.031992488\n",
      "93 drink ear 0.16930717\n",
      "94 father parent 0.44884354\n",
      "95 father daughter 0.30050096\n",
      "96 father brother 0.57814366\n",
      "97 father god 0.25867268\n",
      "98 flower violet 0.16202116\n",
      "99 flower bulb 0.31259528\n",
      "100 flower endurance 0.077140465\n",
      "102 glass metal 0.49442106\n",
      "103 glass magician 0.103495575\n",
      "104 guy stud -0.07769504\n",
      "105 guy partner 0.24692173\n",
      "106 guy girl 0.48165163\n",
      "107 horse mare 0.29968843\n",
      "109 horse ox 0.15778269\n",
      "110 join add 0.16948271\n",
      "111 join marry 0.37529156\n",
      "112 join acquire 0.16268624\n",
      "113 king princess 0.4931812\n",
      "114 king queen 0.55276656\n",
      "115 king rook -0.06602955\n",
      "116 king cabbage 0.016793326\n",
      "117 lose fail 0.25042138\n",
      "118 lose keep 0.265541\n",
      "119 lose get 0.31125098\n",
      "120 man uncle 0.17089534\n",
      "121 man father 0.061748654\n",
      "122 man child 0.21418512\n",
      "123 man victor 0.2890573\n",
      "124 man sentry 0.3216974\n",
      "125 man husband 0.09681622\n",
      "126 man warrior 0.23117124\n",
      "127 man woman 0.6190087\n",
      "128 man governor 0.071570106\n",
      "129 meat bacon 0.10929299\n",
      "131 meat bread 0.5434956\n",
      "132 media radio 0.28183398\n",
      "133 media trading 0.24235983\n",
      "135 money salary 0.41037127\n",
      "136 money pearl 0.010228879\n",
      "137 money diamond 0.390944\n",
      "138 money cash 0.79036\n",
      "140 precedent antecedent 0\n",
      "141 precedent information 0.06895166\n",
      "142 precedent cognition 0.45006886\n",
      "144 precedent group 0.0049930187\n",
      "145 situation condition 0.39801666\n",
      "146 situation conclusion 0.13330273\n",
      "147 situation isolation 0.24686907\n",
      "148 street alley 0.52229685\n",
      "149 street car 0.2523154\n",
      "150 street place 0.043663036\n",
      "151 street avenue 0.15499587\n",
      "155 take obtain 0.27223456\n",
      "156 take receive 0.21867602\n",
      "157 take carry 0.51932836\n",
      "158 take deliver 0.3236676\n",
      "160 take leave 0.34160712\n",
      "161 tiger feline 0.3516927\n",
      "162 tiger carnivore 0.022458661\n",
      "163 tiger mammal 0.045504745\n",
      "164 tiger animal 0.36339974\n",
      "165 tiger organism 0.037889965\n",
      "166 tiger fauna -0.0062284037\n",
      "167 woman secretary 0.20654881\n",
      "168 woman wife 0.3322778\n",
      "172 happy cheerful 0.11747667\n",
      "173 happy young -0.0028395583\n",
      "174 car horn 0.19335505\n",
      "175 car highway 0.5757389\n",
      "176 car gauge 0.04641866\n",
      "177 car cab 0.60762787\n",
      "178 bad immoral 0.26702294\n",
      "179 bad great 0.31235734\n",
      "181 accept deliver 0.3223761\n",
      "182 accept believe 0.45124003\n",
      "0        1\n",
      "1        2\n",
      "2        3\n",
      "3        4\n",
      "4        6\n",
      "      ... \n",
      "145    177\n",
      "146    178\n",
      "147    179\n",
      "148    181\n",
      "149    182\n",
      "Name: 0, Length: 150, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = [] \n",
    "for index, row in test_df.iterrows():\n",
    "    predicted_similarity = cosine_similarity(w2v, row[1], row[2])\n",
    "    data.append([row[0], predicted_similarity])\n",
    "    print(row[0], row[1], row[2], predicted_similarity)\n",
    "output_df = pd.DataFrame(data)\n",
    "print(output_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0         1\n",
      "0      1  0.211073\n",
      "1      2  0.201228\n",
      "2      3  0.672719\n",
      "3      4  0.035309\n",
      "4      6  0.338474\n",
      "..   ...       ...\n",
      "145  177  0.607628\n",
      "146  178  0.267023\n",
      "147  179  0.312357\n",
      "148  181  0.322376\n",
      "149  182  0.451240\n",
      "\n",
      "[150 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "filepath = Path('./10861383-Task1-method-b.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "print(output_df)\n",
    "output_df.to_csv(filepath, index=False, header=False)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
