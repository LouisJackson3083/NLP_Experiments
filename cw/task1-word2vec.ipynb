{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "### Method (b) - Dense Static Representation\n",
    "\n",
    "First we import all the libraries we want for this method, and import the training and test csv's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import re\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_df = pd.read_csv('./Training-dataset.csv')\n",
    "test_df = pd.read_csv('./Task-1-validation-dataset.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's clean up the training dataset's synopses to have no punctuation, tags, numbers or special characters.\n",
    "This will get us an array of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8257/8257 [02:36<00:00, 52.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences & titles to get context from:  394993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_sentences = []\n",
    "for synopsis in tqdm(list(train_df['plot_synopsis'])):\n",
    "    sentences = re.split(r'\\.|\\?|\\!', synopsis) # split the title/synopsis into sentences\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        # for sentence in sent_tokenize(synopsis):\n",
    "        # Remove non-alphabetic characters and convert to lowercase\n",
    "        sentence = re.sub('[^a-zA-Z]', ' ', sentence).lower()\n",
    "        # Tokenise the sentence\n",
    "        sentence = word_tokenize(sentence)\n",
    "        # get a set of the stopwords to remove\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        # Remove stopwords\n",
    "        sentence = [word for word in sentence if word not in stop_words]\n",
    "        # Lemmatize the words\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        sentence = [lemmatizer.lemmatize(word) for word in sentence]\n",
    "    \n",
    "        cleaned_sentences.append(sentence)\n",
    "\n",
    "print(\"Number of sentences & titles to get context from: \", len(cleaned_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the model. This is where all the hyper parameters are set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(cleaned_sentences, vector_size=200, window=10, min_count=1, workers=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a cosine similarity function.\n",
    "\n",
    "This function takes in a model, and 2 words to find the cosine distance between.\n",
    "\n",
    "We return 0 if the word is OOV (out of vocabulary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7855864\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(model, word_a, word_b):\n",
    "    try:\n",
    "        vector_a = model.wv[word_a]\n",
    "    except:\n",
    "        return 0\n",
    "    try:\n",
    "        vector_b = model.wv[word_b]\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "    distance = np.dot(vector_a, vector_b) / (np.linalg.norm(vector_a) * np.linalg.norm(vector_b))\n",
    "    \n",
    "    return distance\n",
    "\n",
    "print(cosine_similarity(w2v, 'bone', 'teeth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 absorb learn 0.27871406\n",
      "2 absorb withdraw 0.54757327\n",
      "3 achieve accomplish 0.82440907\n",
      "4 achieve try -0.00097129494\n",
      "6 acquire get 0.20465411\n",
      "7 acquire obtain 0.84708637\n",
      "8 acquire find 0.1635732\n",
      "11 apple sauce 0.708912\n",
      "12 apple lemon 0.47581014\n",
      "13 apple sunshine 0.5357237\n",
      "14 area region 0.6556919\n",
      "16 area corner 0.3516357\n",
      "17 arm shoulder 0.7911532\n",
      "20 arm body 0.38487807\n",
      "21 arm vein 0.49134395\n",
      "22 arm knee 0.71785605\n",
      "23 arm bone 0.7021116\n",
      "24 arm neck 0.7541852\n",
      "25 ball cannon 0.4482337\n",
      "26 ball basket 0.4906867\n",
      "29 bath trick 0.33768323\n",
      "30 bath wife 0.018425165\n",
      "31 bath balloon 0.5620019\n",
      "32 bed bedroom 0.77677757\n",
      "33 bed blanket 0.6818809\n",
      "34 bed crib 0.71027684\n",
      "35 bed hospital 0.36410213\n",
      "38 bed chair 0.75599235\n",
      "39 belief opinion 0.544694\n",
      "40 belief concept 0.46274665\n",
      "41 belief impression 0.3484203\n",
      "42 belief flower -0.08579012\n",
      "43 bird hawk 0.5242088\n",
      "44 bird turkey 0.49896047\n",
      "45 bird hen 0.4276509\n",
      "46 bird cock 0.5016093\n",
      "48 bone jaw 0.68475544\n",
      "49 bone ankle 0.6763656\n",
      "50 bone knee 0.6837746\n",
      "51 bone neck 0.70980793\n",
      "52 bone teeth 0.7855864\n",
      "53 bone elbow 0.63629764\n",
      "55 book literature 0.59388775\n",
      "56 book story 0.5126138\n",
      "57 book bible 0.7452592\n",
      "58 book topic 0.48574013\n",
      "59 book information 0.34409904\n",
      "60 book essay 0.5516927\n",
      "61 book article 0.7708886\n",
      "62 book theme 0.39956424\n",
      "64 boy brother 0.41301572\n",
      "65 boy soldier 0.30387086\n",
      "67 cat lion 0.6269578\n",
      "68 cat pet 0.6890245\n",
      "69 cat rabbit 0.64753014\n",
      "72 clothes drawer 0.62105\n",
      "73 clothes fabric 0.41882712\n",
      "74 clothes button 0.5422049\n",
      "75 clothes coat 0.81851214\n",
      "76 clothes jacket 0.7332864\n",
      "77 create make 0.29442364\n",
      "80 create destroy 0.69999796\n",
      "81 cup cone 0.5908617\n",
      "82 cup jar 0.6108431\n",
      "83 cup tableware 0\n",
      "84 cup artifact 0.28651997\n",
      "85 cup object 0.5035257\n",
      "86 cup entity 0.19347\n",
      "87 cup food 0.60346645\n",
      "88 cup article 0.19147582\n",
      "89 cup substance 0.3805378\n",
      "90 drink eat 0.7360063\n",
      "91 drink car 0.041909568\n",
      "92 drink mother -0.057239294\n",
      "93 drink ear 0.36988917\n",
      "94 father parent 0.725366\n",
      "95 father daughter 0.5326457\n",
      "96 father brother 0.63009965\n",
      "97 father god 0.23829128\n",
      "98 flower violet 0.56023014\n",
      "99 flower bulb 0.4462602\n",
      "100 flower endurance 0.18203221\n",
      "102 glass metal 0.7887634\n",
      "103 glass magician 0.23904978\n",
      "104 guy stud 0.19364497\n",
      "105 guy partner 0.26244107\n",
      "106 guy girl 0.5175973\n",
      "107 horse mare 0.5023095\n",
      "109 horse ox 0.3582171\n",
      "110 join add 0.0411022\n",
      "111 join marry 0.4210114\n",
      "112 join acquire 0.20796923\n",
      "113 king princess 0.816921\n",
      "114 king queen 0.85593426\n",
      "115 king rook 0.1576447\n",
      "116 king cabbage 0.11259782\n",
      "117 lose fail 0.594198\n",
      "118 lose keep 0.42583025\n",
      "119 lose get 0.3623679\n",
      "120 man uncle 0.12933311\n",
      "121 man father 0.06789003\n",
      "122 man child 0.1050876\n",
      "123 man victor 0.13995208\n",
      "124 man sentry 0.048202332\n",
      "125 man husband 0.18309067\n",
      "126 man warrior 0.16762006\n",
      "127 man woman 0.6036641\n",
      "128 man governor -0.008796398\n",
      "129 meat bacon 0.20055561\n",
      "131 meat bread 0.7208559\n",
      "132 media radio 0\n",
      "133 media trading 0\n",
      "135 money salary 0.605559\n",
      "136 money pearl 0.19227739\n",
      "137 money diamond 0.62407434\n",
      "138 money cash 0.80496436\n",
      "140 precedent antecedent -0.01427922\n",
      "141 precedent information 0.28529933\n",
      "142 precedent cognition 0.7401297\n",
      "144 precedent group 0.26725808\n",
      "145 situation condition 0.59627116\n",
      "146 situation conclusion 0.26188672\n",
      "147 situation isolation 0.3445702\n",
      "148 street alley 0.6099582\n",
      "149 street car 0.4182693\n",
      "150 street place 0.114410885\n",
      "151 street avenue 0.44040555\n",
      "155 take obtain 0.23904692\n",
      "156 take receive 0.16246222\n",
      "157 take carry 0.53255737\n",
      "158 take deliver 0.29071918\n",
      "160 take leave 0.2972035\n",
      "161 tiger feline 0.56967556\n",
      "162 tiger carnivore 0.12308947\n",
      "163 tiger mammal 0.5294933\n",
      "164 tiger animal 0.5769047\n",
      "165 tiger organism 0.35853788\n",
      "166 tiger fauna 0.31663013\n",
      "167 woman secretary 0.12900259\n",
      "168 woman wife 0.35815603\n",
      "172 happy cheerful 0.3751604\n",
      "173 happy young 0.04810876\n",
      "174 car horn 0.35254902\n",
      "175 car highway 0.65094584\n",
      "176 car gauge 0.15587418\n",
      "177 car cab 0.68643576\n",
      "178 bad immoral 0.42366338\n",
      "179 bad great 0.29993993\n",
      "181 accept deliver 0.35547426\n",
      "182 accept believe 0.4718828\n",
      "0        1\n",
      "1        2\n",
      "2        3\n",
      "3        4\n",
      "4        6\n",
      "      ... \n",
      "145    177\n",
      "146    178\n",
      "147    179\n",
      "148    181\n",
      "149    182\n",
      "Name: 0, Length: 150, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = [] \n",
    "for index, row in test_df.iterrows():\n",
    "    predicted_similarity = cosine_similarity(w2v, row[1], row[2])\n",
    "    data.append([row[0], predicted_similarity])\n",
    "    print(row[0], row[1], row[2], predicted_similarity)\n",
    "output_df = pd.DataFrame(data)\n",
    "print(output_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0         1\n",
      "0      1  0.278714\n",
      "1      2  0.547573\n",
      "2      3  0.824409\n",
      "3      4 -0.000971\n",
      "4      6  0.204654\n",
      "..   ...       ...\n",
      "145  177  0.686436\n",
      "146  178  0.423663\n",
      "147  179  0.299940\n",
      "148  181  0.355474\n",
      "149  182  0.471883\n",
      "\n",
      "[150 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "filepath = Path('./10861383-Task1-method-b.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "print(output_df)\n",
    "output_df.to_csv(filepath, index=False, header=False)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
