{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('And', 'CC'), ('now', 'RB'), ('for', 'IN'), ('something', 'NN'), ('completely', 'RB'), ('different', 'JJ')]\n"
     ]
    }
   ],
   "source": [
    "text = word_tokenize(\"And now for something completely different\")\n",
    "print(nltk.pos_tag(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man time day year car moment world house family child country boy\n",
      "state job place way war girl work word\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(word.lower() for word in nltk.corpus.brown.words())\n",
    "print(text.similar('woman'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fly', 'NN')\n",
      "('And now for something completely', 'DIFFERENT')\n"
     ]
    }
   ],
   "source": [
    "tagged_token = nltk.tag.str2tuple('fly/NN')\n",
    "print(tagged_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'AT'), ('Fulton', 'NP-TL'), ...]\n",
      "[('The', 'DET'), ('Fulton', 'NOUN'), ...]\n"
     ]
    }
   ],
   "source": [
    "print(nltk.corpus.brown.tagged_words())\n",
    "print(nltk.corpus.brown.tagged_words(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NOUN', 30654), ('VERB', 14399), ('ADP', 12355), ('.', 11928), ('DET', 11389), ('ADJ', 6706), ('ADV', 3349), ('CONJ', 2717), ('PRON', 2535), ('PRT', 2264), ('NUM', 2166), ('X', 92)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown_news_tagged = brown.tagged_words(categories='news', tagset='universal')\n",
    "tag_fd = nltk.FreqDist(tag for (word, tag) in brown_news_tagged)\n",
    "print(tag_fd.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import ConditionalFreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "sent = \"the the the dog dog some other words that we do not care about\"\n",
    "cfdist = ConditionalFreqDist()\n",
    "for word in word_tokenize(sent):\n",
    "    condition = len(word)\n",
    "    cfdist[condition][word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4\n",
    "Find all POS tags for word ‘promised’ in the Brown POS-tagged corpus (available in NLTK).\n",
    "The lecture slides provide some suggestions as how to start. How long did it take to process the\n",
    "whole corpus? Compare that with your colleagues – is your solution efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VBD', 'VBD', 'VBD', 'VBD', 'VBD', 'VBN', 'VBN', 'VBD', 'VBN', 'VBD', 'VBN', 'VBD', 'VBN', 'VBN', 'VBD', 'VBN', 'VBN', 'VBN', 'VBD', 'VBN', 'VBN', 'VBN', 'VBN', 'JJ', 'VBN', 'VBN', 'VBD', 'VBD', 'VBD', 'VBN', 'VBD', 'VBN', 'VBN', 'VBN', 'VBN', 'VBD', 'VBD', 'VBD', 'VBD', 'VBD', 'VBD', 'VBD', 'VBN', 'VBN', 'VBD']\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(word.lower() for word in nltk.corpus.brown.words())\n",
    "text_tags = nltk.pos_tag(text)\n",
    "promised_POS = []\n",
    "for tag in text_tags:\n",
    "    if tag[0] == 'promised':\n",
    "        promised_POS.append(tag[1])\n",
    "print(promised_POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the' 'DT']\n",
      " ['fulton' 'NN']\n",
      " ['county' 'NN']\n",
      " ...\n",
      " ['was' 'VBD']\n",
      " ['stupefying' 'VBG']\n",
      " ['.' '.']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "text = nltk.Text(word.lower() for word in nltk.corpus.brown.words())\n",
    "text_tags = nltk.pos_tag(text)\n",
    "a = np.array(text_tags)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5\n",
    "Use the POS-tagged Brown corpus (available in NLTK) to estimate word likelihood and tag transition probabilities you would need to be able to disambiguate which of the following two POS tagging results is more likely:\n",
    "\n",
    "    (1) People/NNS continue/VB to/TO inquire/VB the/DT reason/NN for/IN the/AT race/NN for/IN outer/JJ space/NN\n",
    "    \n",
    "    (2) People/NNS continue/VB to/TO inquire/VB the/DT reason/NN for/IN the/AT race/VB for/IN outer/JJ space/NN\n",
    "\n",
    "If necessary, you can use add-one smoothing to estimate the probabilities of words not seen in the corpus.\n",
    "\n",
    "What do the probabilities you have obtained tell you – which of the two POS tags (NN or VB) for word ‘race’ are more likely in this context? Is that the correct POS tag?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\neoni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.probability import FreqDist, ConditionalFreqDist\n",
    "\n",
    "nltk.download('brown')\n",
    "brown_corpus = brown.tagged_sents()\n",
    "word_tag_fd = nltk.FreqDist()\n",
    "tag_transition_fd = nltk.FreqDist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in brown_corpus:\n",
    "    previous_tag = None\n",
    "    for word, tag in sentence:\n",
    "        word_tag_fd[(word, tag)] += 1\n",
    "        if (previous_tag != None):\n",
    "            tag_transition_fd[(previous_tag, tag)] += 1\n",
    "        previous_tag = tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_likelihood(word, tag):\n",
    "    # Smoothing parameters\n",
    "    V = len(word_tag_fd)  # Vocabulary size\n",
    "    N = sum(word_tag_fd.values())  # Total word-tag pairs\n",
    "    smoothing_term = 1.0 / (N + V)\n",
    "\n",
    "    # Calculate smoothed probability\n",
    "    return (word_tag_fd[(word, tag)] + 1) / (N + V) if (word, tag) in word_tag_fd else smoothing_term\n",
    "\n",
    "# Calculate tag transition probabilities with add-one smoothing\n",
    "def calculate_tag_transition_probability(tag1, tag2):\n",
    "    # Smoothing parameters\n",
    "    tags = set(tag for (_, tag) in tag_transition_fd)\n",
    "    V = len(tags)  # Number of unique tags\n",
    "    N = sum(tag_transition_fd.values())  # Total tag transitions\n",
    "    smoothing_term = 1.0 / (N + V)\n",
    "\n",
    "    # Calculate smoothed probability\n",
    "    return (tag_transition_fd[(tag1, tag2)] + 1) / (N + V) if (tag1, tag2) in tag_transition_fd else smoothing_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sentence_probability(sentence):\n",
    "    word_tag_pairs = [word_tag_pair.split('/') for word_tag_pair in sentence]\n",
    "    sentence_probability = 1\n",
    "    previous_tag = None\n",
    "    for word, tag in word_tag_pairs:\n",
    "        word_probability = calculate_word_likelihood(word, tag)\n",
    "        if (previous_tag == None):\n",
    "            sentence_probability *= word_probability\n",
    "        else:\n",
    "            transition_probability = calculate_tag_transition_probability(previous_tag, tag)\n",
    "            sentence_probability *= word_probability * transition_probability\n",
    "        previous_tag = tag\n",
    "    return sentence_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.832576371905368e-67 3.8057610018359524e-73\n",
      "Tagging Result 1 is more likely.\n"
     ]
    }
   ],
   "source": [
    "sentence1 = [\"People/NNS\", \"continue/VB\", \"to/TO\", \"inquire/VB\", \"the/DT\", \"reason/NN\", \"for/IN\", \"the/AT\", \"race/NN\", \"for/IN\", \"outer/JJ\", \"space/NN\"]\n",
    "sentence2 = [\"People/NNS\", \"continue/VB\", \"to/TO\", \"inquire/VB\", \"the/DT\", \"reason/NN\", \"for/IN\", \"the/AT\", \"race/VB\", \"for/IN\", \"outer/JJ\", \"space/NN\"]\n",
    "probability1 = calc_sentence_probability(sentence1)\n",
    "probability2 = calc_sentence_probability(sentence2)\n",
    "print(probability1, probability2)\n",
    "if probability1 > probability2:\n",
    "    print(\"Tagging Result 1 is more likely.\")\n",
    "elif probability2 > probability1:\n",
    "    print(\"Tagging Result 2 is more likely.\")\n",
    "else:\n",
    "    print(\"Both tagging results are equally likely.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New weird idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "from nltk.probability import FreqDist, ConditionalFreqDist\n",
    "text = nltk.Text(word.lower() for word in nltk.corpus.brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tags = nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(text_tags))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
